---
title: "Megan's code for Isoviz"

---


# 230327
Write a function that maps leafcutter cluster data back to isoforms 
- use psl/gtf, advantage of psl is it is compatible with long read generated gtf which lacks UTR info, it will likely become increasingly common to use long read data to determine which isoforms are present in a specific cell type
- input gene name and cell type, start with RBFOX2 and A375
- output is clusters with counts and linked isoforms
- print image filtered for cluster with <=4 junctions but print pdf with all
- if junctions doesn't map back, have a parameter to include/not include as novel
- go back and only plot isoforms with junction supporting data
- eventually also want to call Andrews predictions and get best predicted guide for junction
- could we even have a screen design setting? to scale it up?
- also, can use the code and plots to quantify knockdown
- need to control for library size- tpm of gene?

```{r}
# libraries
require(readr)
require(dplyr)
require(tidyr)
require(magrittr)
require(ggplot2)
require(data.table)
require(stringr)
require(ggpubr)
require(grid)
require(gridExtra)
require(cowplot)
require(Biostrings)
library(ggsci)
require(rempsyc) # for fancy tables: https://cran.r-project.org/web/packages/rempsyc/vignettes/table.html

```

Raw data -> Data for package
Leafcutter clusters
Run this on publicly available data for major cell types
But have function for people to read in their on bam file

Defining Intron clustering with Leafcutter
make a text file with the name of all bed files

module load python/2.7.8

/gpfs/commons/home/mschertzer/knowles_lab/Megan/230320_cas13_validation/junctions

# more stringent- better for calling unique clusters
python ~/Downloads/leafcutter/clustering/leafcutter_cluster_regtools.py -j a375_screen_cells_for_lfc.txt -m 30 -p 0.1 -o a375_screen_cells -l 500000 --includeconst --checkchrom

# moderate stringency
python ~/Downloads/leafcutter/clustering/leafcutter_cluster_regtools.py -j 21c_hESC_RB2_empty_for_lfc.txt -m 20 -p 0.01 -o 21c_hESC_RB2_empty_p.01 -l 500000 --includeconst --checkchrom

# less stringent (-m 5) which is better for detecting all singletons
python ~/Downloads/leafcutter/clustering/leafcutter_cluster_regtools.py -j a375_screen_cells_for_lfc.txt -m 5 -p 0.1 -o a375_screen_cells_5reads -l 500000 --includeconst --checkchrom

python ~/Downloads/leafcutter/clustering/leafcutter_cluster_regtools.py -j 21c_hESC_RB2_empty_for_lfc.txt -m 1 -p 0.01 -o hesc_all_junctions_lfc -l 500000 --includeconst --checkchrom


output is a text file
-p MINCLURATIO, --mincluratio=MINCLURATIO
                        minimum fraction of reads in a cluster that support a
                        junction (default 0.001)
-m MINCLUREADS, --minclureads=MINCLUREADS
                        minimum reads in a cluster (default 30 reads)                       
--includeconst
            also include constitutive introns


Inputs leafcutter clustering output and outputs formatted table
This is old since we use minicutter now
```{r}
# This is data from our A375 screen cells and is the most accurate for our work
# now this includes constitutive exons which have a single junction per cluster
# required 30 total reads per cluster and junction to be 10% of total
clusters <- read_tsv("~/isoviz/data-raw/a375_screen_cells_perind.constcounts.gz", col_names = FALSE, skip = 1) # 59,783
clusters %<>% 
  separate(X1, into = c("coords", "counts"), sep = " ") %>% 
  separate(counts, into = c("junc.counts", "cluster.counts"), sep = "/", convert = TRUE) %>%
  separate(coords, into = c("chr", "start", "end", "name"), sep = ":", convert = TRUE) %>% 
  separate(name, into = c("same", "cluster.n", "extra"), sep = "_") %>% 
  select(-same, -extra)

# remove clusters with no counts
# filter out chrM and chrY clusters
clusters %<>% filter(cluster.counts > 0, chr != "chrY", chr != "chrM") # 15,886

clusters_table = as.data.table(clusters)
save(clusters_table, file = "~/isoviz/data/A375_lfc_clusters.rda")


# HEK293 cells- our data
clusters <- read_tsv("~/isoviz/data-raw/HEK-NFYA-rep2-empty_perind.constcounts.gz", col_names = FALSE, skip = 1) # 46,102
clusters %<>% 
  separate(X1, into = c("coords", "counts"), sep = " ") %>% 
  separate(counts, into = c("junc.counts", "cluster.counts"), sep = "/", convert = TRUE) %>%
  separate(coords, into = c("chr", "start", "end", "name"), sep = ":", convert = TRUE) %>% 
  separate(name, into = c("same", "cluster.n", "extra"), sep = "_") %>% 
  select(-same, -extra)

clusters %<>% filter(cluster.counts > 0, chr != "chrY", chr != "chrM")
clusters_table = as.data.table(clusters)
save(clusters_table, file = "~/isoviz/data/HEK293_lfc_clusters.rda")

# 35738736-36028824
singletons <- read_tsv("~/knowles_lab/Megan/230320_cas13_validation/junctions/HEK-NFYA-rep2-empty_singletons_perind.constcounts.gz", col_names = FALSE, skip = 1)
singletons %<>% 
  separate(X1, into = c("coords", "counts"), sep = " ") %>% 
  separate(counts, into = c("junc.counts", "cluster.counts"), sep = "/", convert = TRUE) %>%
  separate(coords, into = c("chr", "start", "end", "name"), sep = ":", convert = TRUE) %>% 
  separate(name, into = c("same", "cluster.n", "extra"), sep = "_") %>% 
  select(-same, -extra)

singletons %>% filter(chr == "chr22", start >= 35738736, end <= 36028824)


# hESC- our data
clusters <- read_tsv("~/isoviz/data-raw/21c_hESC_RB2_empty_perind.constcounts.gz", col_names = FALSE, skip = 1)
clusters %<>% 
  separate(X1, into = c("coords", "counts"), sep = " ") %>% 
  separate(counts, into = c("junc.counts", "cluster.counts"), sep = "/", convert = TRUE) %>%
  separate(coords, into = c("chr", "start", "end", "name"), sep = ":", convert = TRUE) %>% 
  separate(name, into = c("same", "cluster.n", "extra"), sep = "_") %>% 
  select(-same, -extra)

clusters %<>% filter(cluster.counts > 0, chr != "chrY", chr != "chrM")
clusters_table = as.data.table(clusters)
save(clusters_table, file = "~/isoviz/data/hESC_lfc_clusters.rda")

# hESC- medium stringent
clusters <- read_tsv("~/isoviz/data-raw/21c_hESC_RB2_empty_p.01_perind.constcounts.gz", col_names = FALSE, skip = 1)
clusters %<>% 
  separate(X1, into = c("coords", "counts"), sep = " ") %>% 
  separate(counts, into = c("junc.counts", "cluster.counts"), sep = "/", convert = TRUE) %>%
  separate(coords, into = c("chr", "start", "end", "name"), sep = ":", convert = TRUE) %>% 
  separate(name, into = c("same", "cluster.n", "extra"), sep = "_") %>% 
  select(-same, -extra)

clusters %<>% filter(cluster.counts > 0, chr != "chrY", chr != "chrM")
clusters_table = as.data.table(clusters)
save(clusters_table, file = "~/isoviz/data/hESC_med_string_lfc_clusters.rda")

```

# Consider all junction counts and use gencode annotations to define unique versus common
# this is also irrelevant now since we have minicutter
```{r}
clusters <- read_tsv("~/isoviz/data-raw/hesc_all_junctions_lfc_perind.constcounts.gz", col_names = FALSE, skip = 1)
clusters %<>% 
  separate(X1, into = c("coords", "counts"), sep = " ") %>% 
  separate(counts, into = c("junc.counts", "cluster.counts"), sep = "/", convert = TRUE) %>%
  separate(coords, into = c("chr", "start", "end", "name"), sep = ":", convert = TRUE) %>% 
  separate(name, into = c("same", "cluster.n", "extra"), sep = "_") %>% 
  select(-same, -extra)

clusters %<>% filter(cluster.counts > 0, chr != "chrY", chr != "chrM")
clusters_table = as.data.table(clusters)
save(clusters_table, file = "~/isoviz/data/hESC_all_lfc_junctions.rda")

```


### Potential function #1: ###

Raw data -> Data for package
Gene/transcript name conversion file
Others might want to do this for a different gtf version
```{r}
# could make this a function
# create gene name conversion file from gtf

gtf_convert = function(gtf_file){
  gtf = read_tsv(gtf_file, col_names = FALSE, skip = 5) %>% filter(X3 == "transcript")

  gtf$transcript_id = sapply(strsplit(as.character(gtf$X9), ";"), function(x) x[[2]])
  gtf$transcript_id = sapply(gtf$transcript_id, gsub, pattern = "transcript_id", replacement = "")
  gtf$transcript_id = sapply(as.character(gtf$transcript_id), gsub, pattern = '"', replacement = '')
  gtf$transcript_id = sapply(as.character(gtf$transcript_id), gsub, pattern = ' ', replacement = '')

  gtf$gene_id = sapply(strsplit(as.character(gtf$X9), ";"), function(x) x[[1]])
  gtf$gene_id = sapply(gtf$gene_id, gsub, pattern = "gene_id", replacement = "")
  gtf$gene_id = sapply(as.character(gtf$gene_id), gsub, pattern = '"', replacement = '')
  gtf$gene_id = sapply(as.character(gtf$gene_id), gsub, pattern = ' ', replacement = '')

  gtf$transcript_name = sapply(strsplit(as.character(gtf$X9), ";"), function(x) x[[6]])
  gtf$transcript_name = sapply(gtf$transcript_name, gsub, pattern = "transcript_name", replacement = "")
  gtf$transcript_name = sapply(as.character(gtf$transcript_name), gsub, pattern = '"', replacement = '')
  gtf$transcript_name = sapply(as.character(gtf$transcript_name), gsub, pattern = ' ', replacement = '')

  gtf$gene_name = sapply(strsplit(as.character(gtf$X9), ";"), function(x) x[[4]])
  gtf$gene_name = sapply(gtf$gene_name, gsub, pattern = "gene_name", replacement = "")
  gtf$gene_name = sapply(as.character(gtf$gene_name), gsub, pattern = '"', replacement = '')
  gtf$gene_name = sapply(as.character(gtf$gene_name), gsub, pattern = ' ', replacement = '')

  gtf$gene_type = sapply(strsplit(as.character(gtf$X9), ";"), function(x) x[[3]])
  gtf$gene_type = sapply(gtf$gene_type, gsub, pattern = "gene_type", replacement = "")
  gtf$gene_type = sapply(as.character(gtf$gene_type), gsub, pattern = '"', replacement = '')
  gtf$gene_type = sapply(as.character(gtf$gene_type), gsub, pattern = ' ', replacement = '')

  gtf$transcript_type = sapply(strsplit(as.character(gtf$X9), ";"), function(x) x[[5]])
  gtf$transcript_type = sapply(gtf$transcript_type, gsub, pattern = "transcript_type", replacement = "")
  gtf$transcript_type = sapply(as.character(gtf$transcript_type), gsub, pattern = '"', replacement = '')
  gtf$transcript_type = sapply(as.character(gtf$transcript_type), gsub, pattern = ' ', replacement = '')

  gtf %<>% dplyr::select(gene_id, trans_id = transcript_id, gene_name, transcript_name, gene_type, transcript_type) %>%
    distinct()

}

output = gtf_convert("~/isoviz/data-raw/gencode.v41.basic.annotation.gtf")
write_tsv(output, "~/isoviz/data-raw/gencode_v41_gene-transcript-convert.txt", col_names = TRUE)

```


Add this to original genomedata.R script
```{r}
# modify psl file data to include other gene and transcript names
# currently using gencode basic anntotation file
convert = read_tsv("~/isoviz/data-raw/gencode_v41_gene-transcript-convert.txt", col_names = TRUE)

load("~/isoviz/data/iso_exon_data.rda") # 839,796
iso_data_complete = iso_exon_data %>% left_join(convert, by = c("gene_id", "trans_id"))

save(iso_data_complete, file = "~/isoviz/data/iso_data_complete.rda")

```

Write function to generate intron coords from exon coords- this is currently slow (~30 minutes), can we make the loop more efficient?
This is only done for the gencode gtf for now which would be provided, this chunk would only need to run if people had their own gtf they wanted to use
```{r}
# make psl with intron coords instead of exon
# adapted from genomedata.R

make_intron_coords = function(psl){
  
  mydataset <- fread(psl)

  mydataset$gene_id = sapply(mydataset$V10, function(x){strsplit(x, "_")[[1]][2]})
  mydataset$trans_id = sapply(mydataset$V10, function(x){strsplit(x, "_")[[1]][1]})

  # Get coordinates for each "block"
  mydataset$blocksizes = sapply(mydataset$V19, function(x){paste(strsplit(x, ",")[[1]], collapse=",")})
  mydataset$blockstarts = sapply(mydataset$V21, function(x){paste(strsplit(x, ",")[[1]], collapse=",")})
  mydataset$strand = mydataset$V9
  mydataset$chr = mydataset$V14
  mydataset$start = mydataset$V16
  mydataset$end = mydataset$V17
  mydataset$transcript_length = mydataset$end - mydataset$start

  # Clean up and seperate blocks into rows
  # need to do different adjustments here to get intron coords that will line up with leafcutter
  mydataset = mydataset %>% dplyr::select(chr, start, end, trans_id, gene_id,strand, blocksizes, blockstarts,
                            transcript_length) %>% separate_rows(blocksizes, blockstarts)
  mydataset$blockstarts=as.numeric(mydataset$blockstarts)
  mydataset$blocksizes=as.numeric(mydataset$blocksizes)
  mydataset$blockends = mydataset$blockstarts + mydataset$blocksizes

  transcript_ids = unique(mydataset$trans_id)
  length(transcript_ids) # 116,566
  trans_id = c()
  intron_starts = c()
  intron_ends = c()
  
  # this is the part that is slow
  for(id in transcript_ids){
    data = mydataset %>% filter(trans_id == id)
    new_ends = data$blockstarts[-1] + 1
    len = nrow(data)
    new_starts = data$blockends[-len]
    n = len-1
    trans_id = c(trans_id, rep(id, n))
    intron_starts = c(intron_starts, new_starts)
    intron_ends = c(intron_ends, new_ends)
  }

  # Important note: this no longer has single exon transcripts
  intron_data = data.frame(trans_id, intron_starts, intron_ends) # 723,230

  convert = read_tsv("~/isoviz/data-raw/gencode_v41_gene-transcript-convert.txt", col_names = TRUE)
  trans_info = mydataset %>% select(1, 4, 5, 6) %>% distinct() %>% filter(chr != "chrY", chr != "chrM") 

  data = intron_data %>% left_join(trans_info,  by = "trans_id") %>% 
    left_join(convert, by = c("gene_id", "trans_id")) %>% select(4, 2, 3, 5, 1, 6, 7, 8, 9, 10)

  iso_intron_data = as.data.table(data)

}

iso_intron_data = make_intron_coords("~/isoviz/data-raw/gencode.v41.basic.annotation.psl")
save(iso_intron_data, file = "~/isoviz/data/iso_intron_data.rda")

```

Updated Function: Map junction to isoform: Updated to include all junctions and use gencode annotations to mark unique versus common
How do we incorporate expression here since the hESC data is more deeply sequenced- could combine feature counts when we format the leafcutter output
Using output from minicutter
```{r}

# aggregated for this function
save(gencode_intron_all_data, file = "~/isoviz/data/gencode_intron_all_data.rda")

# this gets read in within function: hESC_all_lfc_junctions.rda

# map junctions function
map_all_junctions = function(gene = "ENSG00000100320", cell_type = "hESC"){
  
  # gencode- this is an updated file containing more junction info
  load(file = "~/isoviz/data/gencode_intron_all_data.rda") # 281,880

  # filter for gene, for now, no need to filter for protein-coding since this gencode set only contains protein-coding
  # this now contains all guide information for this gene
  gene_iso_data = gencode_intron_all_data %>% filter(grepl(gene, gene_id)) # 24
  
  # join iso data with leafcutter data and mark any unannotated junctions
  # consider cell type
  lfc_clusters = paste0(cell_type, "_all_lfc_junctions")
  load(file = paste0("~/isoviz/data/", lfc_clusters, ".rda")) # juncs_recluster
  
  # since leafcutter junctions dont have gene annotations, need to combine here first
  juncs_recluster %<>% select(everything(), junc.counts = readcount) %>% group_by(cluster_idx) %>% mutate(cluster.counts = sum(junc.counts)) %>% ungroup()
  gene_cluster = gene_iso_data %>% 
    left_join(juncs_recluster, by = c("chr" = "chrom", "junc_start" = "start", "junc_end" = "end", "strand")) %>%
    arrange(cluster_idx) # 24
  
  # check minicutter output
  juncs_recluster %>% filter(cluster_idx == "134447")

  name = unique(gene_cluster$gene_name)
  gene_strand = unique(gene_cluster$strand)

  # to get information on leafcutter junctions that don't match annotation
  all_gene_clusters = juncs_recluster %>% filter(cluster_idx %in% gene_cluster$cluster_idx) %>% 
    left_join(gene_iso_data, by = c("chrom" = "chr", "start" = "junc_start", "end" = "junc_end", "strand")) %>%
    filter(is.na(gene_id)) %>% 
    mutate(gene_name = unique(gene_cluster$gene_name), strand = unique(gene_cluster$strand), 
           gene_id = unique(gene_cluster$gene_id), junction_category = "unknown", 
           transcript_isoforms = "unknown", junc_id = paste0("unk.", row_number())) %>%
    select(chr = chrom, junc_start = start, junc_end = end, everything()) %>%
    bind_rows(gene_cluster) %>%
    mutate(junc.counts = ifelse(is.na(cluster_idx), 0, junc.counts), cluster.counts = ifelse(is.na(cluster_idx), 0, cluster.counts)) %>%
    arrange(cluster_idx)
  
  n = all_gene_clusters %>% distinct(cluster_idx, junc_id) %>% group_by(cluster_idx) %>% 
    mutate(junc.per.cluster = ifelse(is.na(cluster_idx), 1, n())) %>% ungroup()
  
  all_gene_clusters %<>% left_join(n, by = c("cluster_idx", "junc_id")) %>%
    mutate(junc.usage = ifelse(junc.counts == 0, 0, round((junc.counts/cluster.counts)*100, digits = 0)), cell_line = paste0(cell_type))
  
  #test
  all_gene_clusters %>% filter(grepl("209", transcript_isoforms)) %>% arrange(junc_start)
  
  # create list of expressed isoforms
  # the logic is that if an isoform has a fully unique junction with no counts, it is unlikely to be expressed
  # I want to be careful here since some junctions won't be represented because of technical issues so only eliminate isoforms where none of their unique junctions have counts, avoid filtering on partially unique for now
  non_expressed_genes = all_gene_clusters %>%
    separate_longer_delim(transcript_isoforms, delim = ",") %>% group_by(transcript_isoforms, junction_category) %>%
    mutate(isoform_counts = ifelse(junction_category == "fully_unique", sum(junc.counts), junc.counts)) %>% 
    filter(junction_category == "fully_unique" & isoform_counts == 0) %>% distinct(transcript_isoforms) %>% ungroup()
  
  uniquely_targetable = all_gene_clusters %>% 
    separate_longer_delim(transcript_isoforms, delim = ",") %>% filter(junction_category == "fully_unique") %>%
    distinct(transcript_isoforms)
  
  partially_targetable = all_gene_clusters %>% 
    separate_longer_delim(transcript_isoforms, delim = ",") %>% filter(junction_category == "partial_unique") %>%
    distinct(transcript_isoforms)

  output = all_gene_clusters %>% 
    separate_longer_delim(transcript_isoforms, delim = ",") %>%
    mutate(transcript_targetable = ifelse(transcript_isoforms %in% uniquely_targetable$transcript_isoforms, "Uniquely", 
                                          ifelse(transcript_isoforms %in% partially_targetable$transcript_isoforms, "Partially", "None"))) %>% 
    mutate(isoform_expressed = ifelse(transcript_isoforms %in% non_expressed_genes$transcript_isoforms, "Unlikely", "Likely")) # 135
  
  if(nrow(output) == 0){
    print(paste0("No junction reads detected for ", name, " in ", cell_type))
  }
  
  return(output)
}

test = map_all_junctions("ENSG00000100320", cell_type = "hESC")
test %>% filter(isoform_expressed == "Likely") %>% distinct(transcript_isoforms)

# chr22	35938897	36028240
```


Updated plotting to go with all junctions output
Now includes minicutter output so all junctions represented
```{r}
load(file='~/isoviz/data/iso_data_complete.rda')
#df = test

# plot isoform plus leafcutter clusters
# add a parameter to only plot a specific junction
plot_all_junction_to_isoform = function(gene = "ENSG00000099875", cell_type = "hESC", junction_usage = 5, include_common_juncs = FALSE, filter_expressed_isoforms = TRUE, filter_all_100percent = FALSE){
  
  # call map_junction function here
  df = map_all_junctions(gene, cell_type)
  
  # filter here based on input parameters- also unknown junctions that belong to common junctions
  if(include_common_juncs == FALSE){
    remove_cluster = df %>% filter(junction_category == "common") %>% select(cluster_idx) %>% distinct()
    df %<>% filter(!cluster_idx %in% remove_cluster$cluster_idx)
  }
  
  if(filter_expressed_isoforms == TRUE){
    df %<>% filter(isoform_expressed == "Likely")
    
     # create list of expressed transcripts
    expressed_isoforms = df %>% filter(isoform_expressed == "Likely", transcript_isoforms != "unknown") %>% 
      separate(col = transcript_isoforms, into = c("name", "transcript")) %>% select(transcript) %>% distinct() %>%
      arrange(transcript) %>%
      mutate(isoforms = paste0(transcript, collapse = ",")) %>% select(isoforms) %>% distinct()
  }
  
  to_remove = df %>% filter(junc.per.cluster == 2 & (junc.usage < junction_usage | junc.usage > (100 - junction_usage)))
  df %<>% filter(!junc_id %in% to_remove$junc_id, junc.counts > 0)
  
  
  # get info after filtering
  name = unique(df$gene_name)
  transcripts = unique(df$transcript_isoforms)
  
  # filter transcripts for plotting too
  gene_data = iso_data_complete %>% filter(transcript_name %in% df$transcript_isoforms)
  
  # setting parameters for the plot based on length of the gene and number of isoforms
  length = max(gene_data$end) - min(gene_data$start)
  min_start = min(gene_data$start)
  n = gene_data %>% group_by(trans_id) %>% tally() %>% nrow()
  y_max = n + 1
  max_end = max(gene_data$end)

  # order the isoforms by length for plotting
  order_plot = gene_data %>% group_by(transcript_name, transcript_length) %>% tally() %>%
    dplyr::arrange(desc(transcript_length), desc(n))
  order_plot$trans_order = 1:nrow(order_plot)
  order_plot = order_plot %>% dplyr::select(transcript_name, trans_order)

  to_plot_ordered = gene_data %>% full_join(order_plot, by = c("transcript_name")) %>%
    arrange(trans_order, blockstarts) 
  to_plot_ordered = to_plot_ordered %>% mutate(seg_end = end)

  # make isoform plot
  p1 = ggplot() +
    geom_segment(aes(x = to_plot_ordered$start, y = to_plot_ordered$trans_order,
                     xend = to_plot_ordered$seg_end, yend = to_plot_ordered$trans_order)) +
    geom_rect(data = to_plot_ordered, mapping = aes(xmin = blockstarts, xmax = blockends, ymin = trans_order - 0.3, ymax = trans_order + 0.3)) +
    xlim(min_start, max_end) + ylim(0,y_max) +
    geom_text(aes(x = Inf, y = to_plot_ordered$trans_order, hjust = -0.1, label = to_plot_ordered$transcript_name), size = 3, check_overlap = TRUE) +
    theme_bw() + ylab("") + xlab("") +
    theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), 
          axis.text.y=element_blank(), axis.ticks.y=element_blank(), legend.position = "top", 
          plot.title = element_text(hjust = 0.5), plot.margin = margin(0.1,1,0,0.1, "in")) +
    ggtitle(paste0(cell_type, ": ", name, " Junction to Isoform Map (" , to_plot_ordered$strand[1], " strand )")) + 
    coord_cartesian(xlim = c(min_start, max_end), clip = 'off')
  
  # new code to plot leafcutter cluster info underneath isoform level data
  # aggregate isoform information
  text = df %>% separate(col = transcript_isoforms, into = c("name", "transcript")) %>% 
    mutate(transcript = ifelse(is.na(transcript), "unknown", transcript)) %>%
    group_by(cluster_idx, junc_id) %>% 
    arrange(cluster_idx, junc_id, transcript) %>%
    mutate(isoforms = paste0(transcript, collapse = ",")) %>%
    select(1:5, junc_id, junction_category, junc.usage, isoforms, junc.per.cluster) %>% distinct() %>% ungroup() %>% 
    mutate(text_plot = paste0(junc.counts, " reads (", junc.usage, "%) : ", isoforms), alpha = junc.usage/100)
  
  clusters = unique(df$cluster_idx)
  introns = df %>% select(-gene_id, -gene_name, -transcript_isoforms) %>% 
    distinct() %>% arrange(cluster_idx, junc.usage)
  introns %<>% left_join(text)
  
  # gets rid of gencode partially unique junctions that are common in this cell type (100% usage) 
  if(filter_expressed_isoforms == TRUE & filter_all_100percent == FALSE){
    remove_junc = introns %>% filter(junc.usage == "100" & isoforms %in% expressed_isoforms$isoforms)
    introns %<>% filter(!junc_id %in% remove_junc$junc_id)
  }else{
    introns %<>% filter(junc.usage != "100")
  }
  
  introns$junc.order = 1:nrow(introns)

  # for guides - remove this or print out?
  for_guides = introns %>% filter(grepl("junc", junc_id))

  p2 = ggplot() + 
    geom_rect(data = introns, mapping = aes(xmin = junc_start, xmax = junc_end, ymin = junc.order - 0.2, ymax = junc.order + 0.2, fill = as.character(cluster_idx), alpha = alpha)) + 
    geom_text(data = introns, aes(x = junc_end, y = junc.order, label = text_plot), hjust = "inward", size = 3) +
    scale_fill_npg() + 
    xlim(min_start, max_end) + theme_bw() + 
    xlab("Hg38 Genomic Position (bp)") + ylab("") + 
    geom_text(data = introns, aes(x = Inf, y = junc.order, hjust = -0.1, label = junc_id), size = 3) + 
    theme(axis.text.y=element_blank(), axis.ticks.y=element_blank(), legend.position = "none", plot.margin = margin(0,1,0,0.1, "in")) +
    coord_cartesian(xlim = c(min_start, max_end), clip = 'off')

  # plot dimenstions based on number of isoforms and junctions
  t = (n + nrow(introns))
  h = t/3
  
  # p1
  if(n <= 4){
    iso_h = n*1.3
  }else{
    iso_h = n*0.8
  }
  
  # p2
  if(nrow(introns) > 6){
    junc_h = nrow(introns) * 0.8
  }else{
    junc_h = nrow(introns) * 1.2
  }
  p1_p2 = plot_grid(p1, p2, ncol = 1, align = "v", rel_heights = c(iso_h, junc_h))
  
  return(p1_p2)
}

#map_all_junctions("ENSG00000001167.15", cell_type = "hESC")
plot_all_junction_to_isoform("ENSG00000100320", cell_type = "hESC") # RBFOX2
ggsave("~/isoviz/plots/rbfox2_hESC_filtered.png", width = 8, height = 5)

plot_all_junction_to_isoform("ENSG00000001167.15", cell_type = "HEK293") # NFYA
ggsave("~/isoviz/plots/nfya_hek293_filtered.png", width = 8, height = 3)

plot_all_junction_to_isoform("ENSG00000099875", cell_type = "hESC", filter_all_100percent = TRUE) # MKNK2
ggsave("~/isoviz/plots/mknk2_filtered.png", width = 8, height = 3)


#df %>% filter(transcript_isoforms == "RBFOX2-209") %>% arrange(junc_start)
```

Function to get guide RNA predictions for specific junctions
```{r}
# merge with gencode info and predictions from 230411_cas13_paper_figures.Rmd
# we should probably filter these for things like runs of T's, etc like we did when designing the screen
# missing 166- which are guides in Harm's screen
v41_info = read_tsv("~/isoviz/data/gencode_v41_all_junction_guides.txt", col_names = TRUE) %>% 
  mutate(guide_sequence = as.character(guide_sequence)) # 2,255,040
predictions = read_csv("/gpfs/commons/groups/knowles_lab/cas13_share/230414_predictions/combined-corrected-predictions-gencode.csv") %>% 
  select(guide_id, predicted_lfc) # 2,254,874

gencode_predictions = v41_info %>% left_join(predictions, by = "guide_id")
#save(gencode_predictions, file = "~/isoviz/data/gencode_predictions.rda")


# need to read in count information a different way- this is just a quick and dirty method
# write a function to get expressed junctions/isoforms and call that within functions?
# some of this is copied from map_all_junctions so should make this a function
junctions = c("junc178149", "junc178148")
junctions = c("junc128207", "junc128208")

junc_list = junctions
get_guide_predictions = function(junc_list, cell_type = "hESC", guides_per_junction = 2){
  load(file = "~/isoviz/data/gencode_predictions.rda")
  filtered_guides = gencode_predictions %>% filter(junc_id %in% junc_list)
  gene_name = unique(filtered_guides$gene_name)
  gene = unique(filtered_guides$gene_id)

  # start function here
  load(file = "~/isoviz/data/gencode_intron_all_data.rda") # 281,880
  gene_iso_data = gencode_intron_all_data %>% filter(grepl(gene, gene_id))
  
  lfc_clusters = paste0(cell_type, "_all_lfc_junctions")
  load(file = paste0("~/isoviz/data/", lfc_clusters, ".rda")) # juncs_recluster

  # since leafcutter junctions dont have gene annotations, need to combine here first
  juncs_recluster %<>% select(everything(), junc.counts = readcount) %>% group_by(cluster_idx) %>% mutate(cluster.counts = sum(junc.counts)) %>% ungroup()
  gene_cluster = gene_iso_data %>% 
    left_join(juncs_recluster, by = c("chr" = "chrom", "junc_start" = "start", "junc_end" = "end", "strand")) %>%
    arrange(cluster_idx) # 24

  # to get information on leafcutter junctions that don't match annotation
  all_gene_clusters = juncs_recluster %>% filter(cluster_idx %in% gene_cluster$cluster_idx) %>% 
    left_join(gene_iso_data, by = c("chrom" = "chr", "start" = "junc_start", "end" = "junc_end", "strand")) %>%
    filter(is.na(gene_id)) %>% 
    mutate(gene_name = unique(gene_cluster$gene_name), strand = unique(gene_cluster$strand), 
           gene_id = unique(gene_cluster$gene_id), junction_category = "unknown", 
           transcript_isoforms = "unknown", junc_id = paste0("unk.", row_number())) %>%
    select(chr = chrom, junc_start = start, junc_end = end, everything()) %>%
    bind_rows(gene_cluster) %>%
    mutate(junc.counts = ifelse(is.na(cluster_idx), 0, junc.counts), cluster.counts = ifelse(is.na(cluster_idx), 0, cluster.counts)) %>%
    arrange(cluster_idx)
  
  n = all_gene_clusters %>% distinct(cluster_idx, junc_id) %>% group_by(cluster_idx) %>% 
    mutate(junc.per.cluster = ifelse(is.na(cluster_idx), 1, n())) %>% ungroup()
  
  all_gene_clusters %<>% left_join(n, by = c("cluster_idx", "junc_id")) %>%
    mutate(junc.usage = ifelse(junc.counts == 0, 0, round((junc.counts/cluster.counts)*100, digits = 0)), cell_line = paste0(cell_type))
  # end here
  
  top_guides = filtered_guides %>%
    group_by(junc_id) %>% slice_min(predicted_lfc, n = guides_per_junction) %>% ungroup()
  
  # make the isoforms shorthand- probably should change in original file
  output = top_guides %>% left_join(all_gene_clusters) %>%
    select(Cluster = cluster_idx, JuncID = junc_id, Category = junction_category, Counts = junc.counts, Usage = junc.usage,
          GuideSeq = guide_sequence, Prediction = predicted_lfc)
  #select(Cluster = cluster_idx, JuncID = junc_id, Category = junction_category, Counts = junc.counts, Usage = junc.usage,Isoforms = transcript_isoforms, GuideID = guide_id, GuideSeq = guide_sequence, Prediction = predicted_lfc)
  # output table
  # don't add sig digits
  fun <- function(x) {formatC(x, format = "f", digits = 0)}

  return(nice_table(output, col.format.custom = 1:5, format.custom = "fun", 
                    title = paste0(gene_name, ": Top ", guides_per_junction, " gRNAs per Junction")))
}

guide_table = get_guide_predictions("ENSG00000100320")

flextable::save_as_docx(guide_table, path = "~/isoviz/plots/230420_rbfox2_guides_table.docx")
```




